{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0cA5bKaePj-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import models\n",
        "from pycocotools.coco import COCO\n",
        "import kagglehub\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "\n",
        "# Download dataset using kagglehub\n",
        "path = kagglehub.dataset_download(\"awsaf49/coco-2017-dataset\")\n",
        "dataset_path = os.path.join(path, 'coco2017')\n",
        "print(\"Updated dataset_path:\", dataset_path)\n",
        "\n",
        "# Check if CUDA is available for faster processing\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Verify dataset structure\n",
        "def verify_dataset_structure(dataset_path):\n",
        "    annotations_dir = os.path.join(dataset_path, 'annotations')\n",
        "    if not os.path.exists(annotations_dir):\n",
        "        print(f\"No annotations directory found at {annotations_dir}. Please verify the dataset structure.\")\n",
        "        print(\"Contents of dataset_path:\", os.listdir(dataset_path))\n",
        "        return False\n",
        "    else:\n",
        "        print(f\"Annotations directory found at {annotations_dir}.\")\n",
        "        print(\"Contents of annotations directory:\", os.listdir(annotations_dir))\n",
        "        return True\n",
        "\n",
        "# Load COCO annotations\n",
        "def load_annotations(annotations_path):\n",
        "    if not os.path.exists(annotations_path):\n",
        "        print(f\"Annotations file not found at {annotations_path}. Please ensure the file is present.\")\n",
        "        return None\n",
        "    coco = COCO(annotations_path)\n",
        "    return coco\n",
        "\n",
        "# Load image and annotations\n",
        "def load_image_and_annotations(img_id, coco, dataset_path):\n",
        "    img_info = coco.loadImgs([img_id])[0]\n",
        "    img_filename = img_info['file_name']\n",
        "    img_path = os.path.join(dataset_path, 'train2017', img_filename)\n",
        "\n",
        "    if not os.path.exists(img_path):\n",
        "        print(f\"Image file not found at {img_path}.\")\n",
        "        return None, None\n",
        "\n",
        "    image = cv2.imread(img_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    ann_ids = coco.getAnnIds(imgIds=[img_id])\n",
        "    annotations = coco.loadAnns(ann_ids)\n",
        "\n",
        "    return image, annotations\n",
        "\n",
        "# Load and apply segmentation model\n",
        "def segment_image(image):\n",
        "    model = models.segmentation.deeplabv3_resnet101(weights='DEFAULT').to(device).eval()\n",
        "    preprocess = T.Compose([\n",
        "        T.ToPILImage(),\n",
        "        T.Resize((520, 520)),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    input_tensor = preprocess(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)['out'][0]\n",
        "        output_predictions = output.argmax(0).byte().cpu().numpy()\n",
        "\n",
        "    return output_predictions\n",
        "\n",
        "# Calculate pixel accuracy, IoU, and F1 score\n",
        "def calculate_metrics(pred_mask, true_mask):\n",
        "    true_mask_resized = cv2.resize(true_mask, (pred_mask.shape[1], pred_mask.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "    intersection = np.logical_and(pred_mask, true_mask_resized)\n",
        "    union = np.logical_or(pred_mask, true_mask_resized)\n",
        "\n",
        "    iou_score = np.sum(intersection) / np.sum(union) if np.sum(union) != 0 else 0\n",
        "    pixel_accuracy = np.sum(pred_mask == true_mask_resized) / true_mask_resized.size\n",
        "\n",
        "    pred_mask_flat = pred_mask.flatten()\n",
        "    true_mask_flat = true_mask_resized.flatten()\n",
        "\n",
        "    f1 = f1_score(true_mask_flat, pred_mask_flat, average='macro', zero_division=1)\n",
        "\n",
        "    return pixel_accuracy, iou_score, f1\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    annotations_path = os.path.join(dataset_path, 'annotations', 'instances_train2017.json')\n",
        "\n",
        "    if not verify_dataset_structure(dataset_path):\n",
        "        return\n",
        "\n",
        "    coco = load_annotations(annotations_path)\n",
        "    if coco is None:\n",
        "        return\n",
        "\n",
        "    img_id = coco.getImgIds()[0]  # Change this ID to test different images\n",
        "    image, annotations = load_image_and_annotations(img_id, coco, dataset_path)\n",
        "\n",
        "    if image is not None and annotations is not None:\n",
        "        pred_mask = segment_image(image)\n",
        "\n",
        "        true_mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
        "        for ann in annotations:\n",
        "            mask = coco.annToMask(ann)\n",
        "            true_mask = np.maximum(true_mask, mask)\n",
        "\n",
        "        pixel_accuracy, iou_score, f1_score_value = calculate_metrics(pred_mask, true_mask)\n",
        "\n",
        "        plt.figure(figsize=(15, 5))\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.title(\"Original Image\")\n",
        "        plt.imshow(image)\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.title(\"Predicted Segmentation\")\n",
        "        plt.imshow(pred_mask, cmap='gray')\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.title(\"True Mask (Resized)\")\n",
        "        plt.imshow(true_mask, cmap='gray')\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "        print(f\"Results for {os.path.join(dataset_path, 'train2017', coco.loadImgs([img_id])[0]['file_name'])}:\")\n",
        "        print(f\"IoU: {iou_score:.4f}\")\n",
        "        print(f\"Pixel Accuracy: {pixel_accuracy:.4f}\")\n",
        "        print(f\"F1 Score: {f1_score_value:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}